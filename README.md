Project: Smart Waste Sorting System
ğŸ“Œ Overview
This project implements a smart waste classification system using an Arduino Nano 33 BLE Sense with an OV7670 camera, a Raspberry Pi (RPi) for inference, and Bluetooth communication between them.

When an object is detected via a touch sensor, the Arduino captures an image, sends it to the RPi via Bluetooth (using BluPy), and the RPi runs a pre-trained CNN model (model.h5) to classify the object into one of six categories:

cardboard

metal

paper

plastic

trash

white-glass

After classification, the RPi activates a motor (via GPIO) to sort the waste and prints the detected class in the terminal.

ğŸ›  Hardware Components
Arduino Nano 33 BLE Sense (with BLE support)

OV7670 Camera Module (for image capture)

Capacitive Touch Sensor (to detect object presence)

Raspberry Pi (for running the ML model)

Servo Motor / Stepper Motor (for waste sorting)

Jumper Wires & Breadboard (for connections)

ğŸ“‚ Repository Structure

Smart-Waste-Sorter/  
â”œâ”€â”€ Arduino/  
â”‚   â”œâ”€â”€ waste_sorter_ble.ino       # Arduino BLE & Camera Code  
â”‚   â””â”€â”€ ov7670_config.h            # OV7670 Camera Settings  
â”œâ”€â”€ RaspberryPi/  
â”‚   â”œâ”€â”€ bluetooth_receiver.py      # BluPy Bluetooth Receiver  
â”‚   â”œâ”€â”€ classify_waste.py          # CNN Model Inference  
â”‚   â””â”€â”€ model.h5                   # Pre-trained Keras Model  
â”œâ”€â”€ Docs/  
â”‚   â”œâ”€â”€ wiring_diagram.png         # Hardware Connections  
â”‚   â””â”€â”€ demo_video.mp4             # System Demo  
â””â”€â”€ README.md                      # This File  

âš™ï¸ How It Works
1ï¸âƒ£ Arduino Nano 33 BLE Sense (Sender)
Touch Sensor Detection:

When an object is placed near the sensor, it triggers the camera.

OV7670 Camera Capture:

Captures a 320x240 grayscale image (optimized for BLE transfer).

Bluetooth Low Energy (BLE) Transmission:

Creates a custom BLE service (BLE_SERVICE_UUID) and sends the image data.

2ï¸âƒ£ Raspberry Pi (Receiver & Classifier)
Bluetooth Data Reception (bluetooth_receiver.py):

Uses BluPy to receive the image from Arduino.

CNN Model Inference (classify_waste.py):

Loads the pre-trained model.h5 (Keras/TensorFlow).

Classifies the image into one of 6 waste categories.

Motor Control & Output:

Activates a GPIO-controlled motor to sort the waste.

Prints the detected class (e.g., "Detected: plastic").

ğŸ”Œ Wiring Guide
Arduino Nano 33 BLE Sense
OV7670 Pin	Arduino Pin
VCC	3.3V
GND	GND
SIOC	SCL
SIOD	SDA
VSYNC	D9
HREF	D8
PCLK	D11
XCLK	D3
D0-D7	D4-D10
Touch Sensor â†’ A0 (Analog Input)

Raspberry Pi
Motor â†’ GPIO17 (or any PWM-capable pin)

Bluetooth â†’ Built-in (using BluPy library)

ğŸš€ Setup & Execution
1. Flash Arduino Code
Upload waste_sorter_ble.ino to the Arduino Nano 33 BLE Sense.

Ensure ov7670_config.h is properly configured.

2. Raspberry Pi Setup
# Install dependencies  
pip install tensorflow numpy blupy RPi.GPIO  

# Run the receiver & classifier  
python3 bluetooth_receiver.py  
python3 classify_waste.py  

3. Test the System
Place an object near the touch sensor.

Arduino captures & sends the image via BLE.

RPi classifies it and prints the result.

Motor moves to sort the waste.

ğŸ“Š Expected Output

[Bluetooth] Image received from Arduino.  
[Model] Loading model.h5...  
[Prediction] Detected: metal (92% confidence)  
[GPIO] Activating motor for metal sorting...  

ğŸ“œ License
MIT License - Free for personal & educational use.
